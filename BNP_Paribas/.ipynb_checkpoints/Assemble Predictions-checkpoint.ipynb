{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#combining predictions so far\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "DATA_DIR = \"/Users/patrickkennedy/Desktop/Data_Science/Kaggle/BNP_Paribas/Predictions/\"\n",
    "\n",
    "pred1 = pd.read_csv(DATA_DIR + \"ada_boosted_extra_trees_jitteredrandomstate_250iterations.csv\")\n",
    "pred2 = pd.read_csv(DATA_DIR + \"extra_trees_and_log_and_gradientboost_jitteredrandomstate_295iterations.csv\")\n",
    "pred3 = pd.read_csv(DATA_DIR + \"extra_trees_classifier_jitteredrandomstate_1000iterations_engineeredfeatures.csv\")\n",
    "pred4 = pd.read_csv(DATA_DIR + \"extra_trees_jitteredrandomstate_250iterations.csv\")\n",
    "pred5 = pd.read_csv(DATA_DIR + \"extra_trees_jitteredrandomstate_5000iterations.csv\")\n",
    "pred6 = pd.read_csv(DATA_DIR + \"XGBClassifier_jitteredrandomstate_250iterations.csv\")\n",
    "pred7 = pd.read_csv(DATA_DIR + \"NN-sigmoid64-softmax_jitteredrandomstate_25iterations_engineeredfeatures.csv\")\n",
    "pred8 = pd.read_csv(DATA_DIR + \"XGBoost-native_jitteredrandomstate_25iterations_engineeredfeatures.csv\")\n",
    "pred9 = pd.read_csv(DATA_DIR + \"gradientboost_jitteredrandomstate_100iterations.csv\")\n",
    "pred10 = pd.read_csv(DATA_DIR + \"autolearn.csv\")\n",
    "pred11 = pd.read_csv(DATA_DIR + \"NN-rectifier100-tanh100-softmax_jitteredrandomstate_10iterations_engineeredfeatures.csv\")\n",
    "\n",
    "\n",
    "pred_list = [pred1, pred2, pred3, pred4, pred5, pred6, pred7, pred8, pred9, pred10, pred11]\n",
    "ids = pred1.ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "predictions = []\n",
    "for pred in pred_list:\n",
    "    predictions.append(pred.PredictedProb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pd.DataFrame({\"ID\": ids, \"PredictedProb\": np.mean(predictions, axis=0)}).to_csv('Results_of_6_models.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.44364004,  0.83400556,  0.712109  , ...,  0.81756754,\n",
       "        0.89852303,  0.55387757])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(predictions, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>4</th>\n",
       "      <th>8</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.719749</td>\n",
       "      <td>0.836000</td>\n",
       "      <td>0.732872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.719749</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.742571</td>\n",
       "      <td>0.721993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.836000</td>\n",
       "      <td>0.742571</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.734198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.732872</td>\n",
       "      <td>0.721993</td>\n",
       "      <td>0.734198</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           4         8        10        11\n",
       "4   1.000000  0.719749  0.836000  0.732872\n",
       "8   0.719749  1.000000  0.742571  0.721993\n",
       "10  0.836000  0.742571  1.000000  0.734198\n",
       "11  0.732872  0.721993  0.734198  1.000000"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.DataFrame()\n",
    "\n",
    "data['1'] = pred1['PredictedProb']\n",
    "data['2'] = pred2['PredictedProb']\n",
    "data['3'] = pred3['PredictedProb']\n",
    "data['4'] = pred4['PredictedProb']\n",
    "data['5'] = pred5['PredictedProb']\n",
    "data['6'] = pred6['PredictedProb']\n",
    "data['7'] = pred7['PredictedProb']\n",
    "data['8'] = pred8['PredictedProb']\n",
    "data['9'] = pred9['PredictedProb']\n",
    "data['10'] = pred10['PredictedProb']\n",
    "data['11'] = pred11['PredictedProb']\n",
    "\n",
    "data.drop(['6','7','9','2','3','1','5'],axis=1).corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#submitted pred4 and pred6... but what about averaging pred6 against every single one?\n",
    "predictions = []\n",
    "predictions.append(pred4.PredictedProb*0.67)\n",
    "predictions.append(pred6.PredictedProb*0.33)\n",
    "pd.DataFrame({\"ID\": ids, \"PredictedProb\": np.sum(predictions, axis=0)}).to_csv('Results_of_2_uncorrelated_models.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#so that seems to work! get a bunch of uncorrelated models together... best way to jump up leaderboard!\n",
    "predictions = []\n",
    "predictions.append(pred4.PredictedProb*0.5)\n",
    "predictions.append(pred7.PredictedProb*0.5)\n",
    "\n",
    "pd.DataFrame({\"ID\": ids, \"PredictedProb\": np.sum(predictions, axis=0)}).to_csv('Results_of_NNandExtraTrees_uncorrelated_models.csv',index=False)\n",
    "#gives .462.. a bit behind here...\n",
    "\n",
    "#also think of putting all the models together again? find all the uncorrelated models:\n",
    "#right now preds1-5 are alike, 6-7 are alike\n",
    "\n",
    "#i can change the structure of the NN to see if that makes a difference too\n",
    "#i want a series of uncorrelated models!!\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1690977849810913"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#next steps are to rerun xgbclassifier with random params, gradient boost with random params, \n",
    "#maybe a NN with random params\n",
    "#blending models together that are uncorrelated and with appropriate weights (how to optimize?)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
