{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "DATA_DIR = \"/Users/patrickkennedy/Desktop/Data_Science_MISC/Kaggle\"\n",
    "train = pd.read_csv(DATA_DIR + \"/BNP_Paribas/train.csv\")\n",
    "test = pd.read_csv(DATA_DIR + \"/BNP_Paribas/test.csv\")\n",
    "all_data = pd.concat([train, test], axis=0)\n",
    "all_data = all_data.reset_index()\n",
    "pd.set_option('display.max_columns', None)\n",
    "foo = lambda x: pd.Series([i for i in reversed(list(str(x)))])\n",
    "v22 = all_data['v22'].apply(foo)\n",
    "v22.rename(columns={0:'v22-0',1:'v22-1',2:'v22-2', 3:'v22-3'},inplace=True)\n",
    "v22 = v22.replace(to_replace='[a-z]', value=-1, regex=True)\n",
    "\n",
    "v56 = all_data['v56'].apply(foo)\n",
    "v56.rename(columns={0:'v56-0',1:'v56-1',2:'v56-2'},inplace=True)\n",
    "v56 = v56.replace(to_replace='[a-z]', value=-1, regex=True)\n",
    "\n",
    "v125 = all_data['v125'].apply(foo)\n",
    "v125.rename(columns={0:'v125-0',1:'v125-1',2:'v125-2'},inplace=True)\n",
    "v125 = v125.replace(to_replace='[a-z]', value=-1, regex=True)\n",
    "data = pd.concat([all_data, v22, v56, v125], axis=1)\n",
    "data = data.drop(['v22', 'v56', 'v125'], axis=1)\n",
    "\n",
    "data.fillna(-1, inplace=True)\n",
    "\n",
    "categorical = []\n",
    "\n",
    "for col in data.columns:\n",
    "    s = str(data[col][0])\n",
    "    d = str(data[col][1])\n",
    "    f = str(data[col][2])\n",
    "    g = str(data[col][3])\n",
    "    h = str(data[col][4])\n",
    "    try:\n",
    "        float(s)\n",
    "        float(d)\n",
    "        float(f)\n",
    "        float(g)\n",
    "        float(h)\n",
    "        \n",
    "    except ValueError:\n",
    "        categorical.append(col)\n",
    "\n",
    "for cat in categorical:\n",
    "    data[cat] = pd.factorize(data[cat])[0]\n",
    "    \n",
    "data['mean'] = data.mean(axis=1)\n",
    "data['max'] = data.max(axis=1)\n",
    "data['min'] = data.min(axis=1)\n",
    "data['sum'] = data.sum(axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5664 1 []\n",
      "{'objective': 'binary:logistic', 'eta': 0.083, 'max_depth': 4, 'min_child_weight': 6}\n",
      "[ 0.15199339  0.87649053  0.85952497 ...,  0.83490026  0.86928219\n",
      "  0.43194804]\n",
      "2181 2 [5664]\n",
      "{'objective': 'binary:logistic', 'eta': 0.048, 'max_depth': 9, 'min_child_weight': 15}\n",
      "[ 0.15579863  0.87168652  0.77954632 ...,  0.7980864   0.91661507\n",
      "  0.44789368]\n",
      "695 3 [5664, 2181]\n",
      "{'objective': 'binary:logistic', 'eta': 0.073, 'max_depth': 8, 'min_child_weight': 34}\n",
      "[ 0.18272866  0.82333374  0.76973146 ...,  0.79727739  0.90281701\n",
      "  0.45953292]\n",
      "3684 4 [5664, 2181, 695]\n",
      "{'objective': 'binary:logistic', 'eta': 0.092, 'max_depth': 6, 'min_child_weight': 94}\n",
      "[ 0.17798856  0.8806591   0.76508015 ...,  0.83133191  0.89314187\n",
      "  0.40835437]\n",
      "1131 5 [5664, 2181, 695, 3684]\n",
      "{'objective': 'binary:logistic', 'eta': 0.093, 'max_depth': 4, 'min_child_weight': 95}\n",
      "[ 0.194728    0.86965871  0.81748164 ...,  0.84512353  0.90142918\n",
      "  0.40926424]\n",
      "6097 6 [5664, 2181, 695, 3684, 1131]\n",
      "{'objective': 'binary:logistic', 'eta': 0.038, 'max_depth': 8, 'min_child_weight': 73}\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-be508d7176c0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     56\u001b[0m     }\n\u001b[1;32m     57\u001b[0m     \u001b[0;32mprint\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxgb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxgtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m250\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/patrickkennedy/anaconda/lib/python2.7/site-packages/xgboost/training.pyc\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(params, dtrain, num_boost_round, evals, obj, feval, maximize, early_stopping_rounds, evals_result, verbose_eval, learning_rates, xgb_model)\u001b[0m\n\u001b[1;32m    119\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mearly_stopping_rounds\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_boost_round\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 121\u001b[0;31m             \u001b[0mbst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    122\u001b[0m             \u001b[0mnboost\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevals\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/patrickkennedy/anaconda/lib/python2.7/site-packages/xgboost/core.pyc\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, dtrain, iteration, fobj)\u001b[0m\n\u001b[1;32m    692\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    693\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mfobj\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 694\u001b[0;31m             \u001b[0m_check_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_LIB\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mXGBoosterUpdateOneIter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miteration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    695\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    696\u001b[0m             \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import csv\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier, AdaBoostClassifier, GradientBoostingClassifier\n",
    "from sklearn import ensemble\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import random\n",
    "from xgboost import XGBClassifier\n",
    "import xgboost as xgb\n",
    "from sknn.mlp import Classifier, Layer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "#print('Load data...')\n",
    "train = data[data[\"target\"]>=0]\n",
    "test = data[data[\"target\"]<0]\n",
    "\n",
    "cols_to_drop = ['ID', 'index', 'target']\n",
    "target = train['target'].values\n",
    "train = train.drop(cols_to_drop, axis=1)\n",
    "id_test = test['ID'].values\n",
    "test_target = test['target'].values\n",
    "test = test.drop(['ID', 'index', 'target'],axis=1)\n",
    "\n",
    "y_pred = []\n",
    "holder = []\n",
    "\n",
    "#X_train, X_test, y_train, y_test = train_test_split(train, target, test_size=0.33, random_state=42)\n",
    "\n",
    "for i in range(25):\n",
    "    \n",
    "    dummy = random.randint(1,10000)\n",
    "    x = True\n",
    "    while x == True:\n",
    "        print dummy, str(len(holder)+1), holder\n",
    "        #print holder\n",
    "        if dummy in holder:\n",
    "            dummy = random.randint(1,10000)\n",
    "        else:\n",
    "            x = False\n",
    "    holder.append(dummy)\n",
    "    \n",
    "    random.seed(dummy)\n",
    "\n",
    "    xgtrain = xgb.DMatrix(train, target)\n",
    "    xgtest = xgb.DMatrix(test, label=test_target)\n",
    "    \n",
    "    params = {\n",
    "        \"objective\":\"binary:logistic\",\n",
    "        \"min_child_weight\":random.randint(1,100),\n",
    "        \"eta\":float(random.randint(1,100)/1000.0),\n",
    "        \"max_depth\":random.randint(4,12)\n",
    "    }\n",
    "    print params\n",
    "    model = xgb.train(params, xgtrain, 250) \n",
    "    \n",
    "    \n",
    "    y_pred.append(model.predict(xgtest, ntree_limit=model.best_iteration))\n",
    "    print y_pred[-1]\n",
    "    \n",
    "pd.DataFrame({\"ID\": id_test, \"PredictedProb\": np.mean(y_pred, axis=0)}).to_csv('XGBoost-native_randomparams_25iters_engineeredfeatures.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([ 0.02808106,  0.95732737,  0.2404487 , ...,  0.58100545,\n",
       "         0.93124896,  0.19091085], dtype=float32)]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#what about taking the correlation of each set of predictions in the model (y_pred) before it averages?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
