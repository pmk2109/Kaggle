{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load the data using pandas\n",
      "Eliminate missing values\n",
      "[('colsample_bytree', 0.8645938750638906), ('silent', 1), ('max_delta_step', 6.650258122365785), ('min_child_weight', 50.31287747915195), ('subsample', 0.8902686232425377), ('eta', 0.038968208713327845), ('objective', 'reg:linear'), ('max_depth', 10), ('gamma', 0.8374592697309676)]\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "t0 = time.clock()\n",
    "\n",
    "import pandas as pd \n",
    "import numpy as np \n",
    "import xgboost as xgb\n",
    "from xgboost import XGBClassifier, XGBRegressor\n",
    "from scipy.optimize import fmin_powell\n",
    "from ml_metrics import quadratic_weighted_kappa\n",
    "from sklearn import grid_search\n",
    "\n",
    "def eval_wrapper(yhat, y):  \n",
    "    y = np.array(y)\n",
    "    y = y.astype(int)\n",
    "    yhat = np.array(yhat)\n",
    "    yhat = np.clip(np.round(yhat), np.min(y), np.max(y)).astype(int)   \n",
    "    return quadratic_weighted_kappa(yhat, y)\n",
    "    \n",
    "def get_params():\n",
    "    \n",
    "    params = {}\n",
    "    params[\"objective\"] = \"reg:linear\"     \n",
    "    params[\"eta\"] = 0.038968208713327845\n",
    "    params[\"gamma\"] = 0.83745926973096763\n",
    "    params[\"max_delta_step\"] = 6.6502581223657851\n",
    "    params[\"min_child_weight\"] = 50.31287747915195\n",
    "    params[\"subsample\"] = 0.89026862324253775\n",
    "    params[\"colsample_bytree\"] = 0.86459387506389063\n",
    "    params[\"silent\"] = 1\n",
    "    params[\"max_depth\"] = 10\n",
    "    plst = list(params.items())\n",
    "    return plst\n",
    "    \n",
    "def apply_offset(data, bin_offset, sv, scorer=eval_wrapper):\n",
    "    # data has the format of pred=0, offset_pred=1, labels=2 in the first dim\n",
    "    data[1, data[0].astype(int)==sv] = data[0, data[0].astype(int)==sv] + bin_offset\n",
    "    score = scorer(data[1], data[2])\n",
    "    return score\n",
    "\n",
    "\n",
    "# global variables\n",
    "columns_to_drop = ['Id', 'Response']\n",
    "xgb_num_rounds = 500 #5000 gives me good score (~15 min), 10000 (~32 min) (no improvement)\n",
    "num_classes = 8\n",
    "\n",
    "print(\"Load the data using pandas\")\n",
    "\n",
    "DATA_TRAIN_PATH = '/Users/patrickkennedy/Desktop/Project DATA/train.csv'\n",
    "DATA_TEST_PATH = '/Users/patrickkennedy/Desktop/Project DATA/test.csv'\n",
    "\n",
    "\n",
    "train = pd.read_csv(DATA_TRAIN_PATH)\n",
    "test = pd.read_csv(DATA_TEST_PATH)\n",
    "\n",
    "# combine train and test\n",
    "all_data = train.append(test)\n",
    "print('Eliminate missing values')    \n",
    "# Use -1 for any others\n",
    "all_data.fillna(-1, inplace=True)\n",
    "\n",
    "all_data['Product_Info_2'] = pd.factorize(all_data['Product_Info_2'])[0]\n",
    "\n",
    "# fix the dtype on the label column\n",
    "all_data['Response'] = all_data['Response'].astype(int)\n",
    "\n",
    "# Provide split column\n",
    "#all_data_new['Split'] = np.random.randint(5, size=all_data_new.shape[0])\n",
    "\n",
    "# split train and test\n",
    "train = all_data[all_data['Response']>0].copy()\n",
    "test = all_data[all_data['Response']<1].copy()\n",
    "\n",
    "#y = train['Response']\n",
    "#y_test = test['Response']\n",
    "#train = train.drop(columns_to_drop, axis=1)\n",
    "#test = test.drop(columns_to_drop, axis=1)\n",
    "    \n",
    "# convert data to xgb data structure\n",
    "xgtrain = xgb.DMatrix(train.drop(columns_to_drop, axis=1), train['Response'].values)\n",
    "xgtest = xgb.DMatrix(test.drop(columns_to_drop, axis=1), label=test['Response'].values)    \n",
    "\n",
    "# get the parameters for xgboost\n",
    "plst = get_params()\n",
    "print plst      \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = xgb.train(plst, xgtrain, xgb_num_rounds) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Train score is:', 0.748203457801927)\n",
      "Optimization terminated successfully.\n",
      "         Current function value: -0.748203\n",
      "         Iterations: 1\n",
      "         Function evaluations: 14\n",
      "Optimization terminated successfully.\n",
      "         Current function value: -0.752895\n",
      "         Iterations: 1\n",
      "         Function evaluations: 14\n",
      "Optimization terminated successfully.\n",
      "         Current function value: -0.768901\n",
      "         Iterations: 2\n",
      "         Function evaluations: 40\n",
      "Optimization terminated successfully.\n",
      "         Current function value: -0.781453\n",
      "         Iterations: 2\n",
      "         Function evaluations: 72\n",
      "Optimization terminated successfully.\n",
      "         Current function value: -0.784528\n",
      "         Iterations: 2\n",
      "         Function evaluations: 93\n",
      "Optimization terminated successfully.\n",
      "         Current function value: -0.784659\n",
      "         Iterations: 2\n",
      "         Function evaluations: 51\n",
      "Optimization terminated successfully.\n",
      "         Current function value: -0.786547\n",
      "         Iterations: 2\n",
      "         Function evaluations: 86\n",
      "Optimization terminated successfully.\n",
      "         Current function value: -0.799053\n",
      "         Iterations: 2\n",
      "         Function evaluations: 38\n",
      "229.645403\n"
     ]
    }
   ],
   "source": [
    "# get preds\n",
    "train_preds = model.predict(xgtrain, ntree_limit=model.best_iteration)\n",
    "print('Train score is:', eval_wrapper(train_preds, train['Response'].values)) \n",
    "test_preds = model.predict(xgtest, ntree_limit=model.best_iteration)\n",
    "\n",
    "\n",
    "#where to digitize? here instead of the clipping?... by digitizing we get a better first guess? i guess...\n",
    "\n",
    "bins = np.array([0.0, 1.0, 2.5, 3.2, 3.6, 4.0, 10.0])  #change these bins and test the result, juke up the stats\n",
    "                                                       #is there a way to use an optimization function for these?\n",
    "\n",
    "train_preds = np.clip(train_preds, -0.99, 8.99)\n",
    "test_preds = np.clip(test_preds, -0.99, 8.99)\n",
    "\n",
    "# train offsets \n",
    "#or here in the offset function?\n",
    "offsets = np.ones(num_classes) * -0.5\n",
    "offset_train_preds = np.vstack((train_preds, train_preds, train['Response'].values))\n",
    "\n",
    "for j in range(num_classes):\n",
    "    train_offset = lambda x: -apply_offset(offset_train_preds, x, j)\n",
    "    offsets[j] = fmin_powell(train_offset, offsets[j])  \n",
    "\n",
    "\n",
    "# apply offsets to test\n",
    "data = np.vstack((test_preds, test_preds, test['Response'].values))\n",
    "for j in range(num_classes):\n",
    "    data[1, data[0].astype(int)==j] = data[0, data[0].astype(int)==j] + offsets[j]    \n",
    "final_test_preds = np.round(np.clip(data[1], 1, 8)).astype(int)\n",
    "\n",
    "\n",
    "\n",
    "preds_out = pd.DataFrame({\"Id\": test['Id'].values, \"Response\": final_test_preds})\n",
    "preds_out = preds_out.set_index('Id')\n",
    "preds_out.to_csv('xgb_offset_submission.csv')\n",
    "\n",
    "print time.clock()-t0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# train offsets \n",
    "#set initial guess for offsets at 0\n",
    "offsets = np.array(range(num_classes))*0\n",
    "\n",
    "#stack the data in three cols, apply offsets to data[1] given member of particular class (daat[0].astype(int)==j)\n",
    "data = np.vstack((train_preds, train_preds, train['Response'].values))\n",
    "for j in range(num_classes):\n",
    "    data[1, data[0].astype(int)==j] = data[0, data[0].astype(int)==j] + offsets[j] \n",
    "\n",
    "#apply fmin_powell to each class in order 1,2,3,4,5,6,7,8    \n",
    "for j in range(num_classes):\n",
    "    train_offset = lambda x: -apply_offset(data, x, j)\n",
    "    offsets[j] = fmin_powell(train_offset, offsets[j])  \n",
    "\n",
    "\n",
    "# apply offsets to test\n",
    "data = np.vstack((test_preds, test_preds, test['Response'].values))\n",
    "for j in range(num_classes):\n",
    "    data[1, data[0].astype(int)==j] = data[0, data[0].astype(int)==j] + offsets[j] \n",
    "\n",
    "    \n",
    "#force structure of final predictions to be in range 1-8\n",
    "final_test_preds = np.round(np.clip(data[1], 1, 8)).astype(int)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(range(8))*0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import itertools\n",
    "dum = [x for x in itertools.permutations([0, 1, 2, 3, 4, 5, 6, 7])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40320"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40320"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "56*30*24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
