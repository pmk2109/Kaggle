{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(59381, 126) (59381,)\n",
      "RandomizedSearchCV took 112468.81 seconds for 50 candidates parameter settings.\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.579 (std: 0.002)\n",
      "Parameters: {'colsample_bytree': 0.9, 'learning_rate': 0.01, 'max_delta_step': 1, 'min_child_weight': 82, 'n_estimators': 666, 'subsample': 0.75, 'objective': 'multi:softmax', 'max_depth': 11, 'gamma': 2}\n",
      "\n",
      "Model with rank: 2\n",
      "Mean validation score: 0.577 (std: 0.001)\n",
      "Parameters: {'colsample_bytree': 1, 'learning_rate': 0.03, 'max_delta_step': 4, 'min_child_weight': 86, 'n_estimators': 877, 'subsample': 0.75, 'objective': 'multi:softmax', 'max_depth': 10, 'gamma': 8}\n",
      "\n",
      "Model with rank: 3\n",
      "Mean validation score: 0.569 (std: 0.003)\n",
      "Parameters: {'colsample_bytree': 0.5, 'learning_rate': 0.001, 'max_delta_step': 4, 'min_child_weight': 1, 'n_estimators': 384, 'subsample': 0.5, 'objective': 'multi:softmax', 'max_depth': 7, 'gamma': 2}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#using randomizedsearchCV takes much less time\n",
    "#try using MOE? how?\n",
    "\n",
    "#begin developing structure of the presentation and beef up on what the hell XGBoost, QWK, fmin_powell, and the rest are doing\n",
    "\n",
    "\n",
    "from sklearn.grid_search import GridSearchCV, RandomizedSearchCV\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.stats import randint\n",
    "from xgboost import XGBClassifier, XGBRegressor\n",
    "from time import time\n",
    "from operator import itemgetter\n",
    "\n",
    "\n",
    "\n",
    "DATA_DIR = '/Users/patrickkennedy/Desktop'\n",
    "train = pd.read_csv(DATA_DIR + '/Project DATA/train.csv')\n",
    "test = pd.read_csv(DATA_DIR + '/Project DATA/test.csv')\n",
    "\n",
    "train['Product_Info_2'] = pd.factorize(train['Product_Info_2'])[0]\n",
    "test['Product_Info_2'] = pd.factorize(test['Product_Info_2'])[0]\n",
    "\n",
    "train.fillna(-1, inplace=True)\n",
    "test.fillna(-1, inplace=True)\n",
    "\n",
    "\n",
    "features = train.columns\n",
    "features = features.drop(\"Id\")\n",
    "features = features.drop(\"Response\")\n",
    "X = train[features]\n",
    "y = train[\"Response\"]\n",
    "\n",
    "print X.shape, y.shape\n",
    "\n",
    "\n",
    "X_test = test[features]\n",
    "\n",
    "dev_cutoff = len(Y) * 4/5\n",
    "X_dev = X[:dev_cutoff]\n",
    "y_dev = y[:dev_cutoff]\n",
    "X_test = X[dev_cutoff:]\n",
    "y_test = y[dev_cutoff:]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#using something other than randint... we don't want to round numbers here (for some cases)\n",
    "\n",
    "param_dist = {\"objective\": [\"reg:linear\", \"count:poisson\", \"multi:softmax\"],\n",
    "                      \"learning_rate\": [0.001, 0.01, 0.03],\n",
    "                      \"gamma\": randint(0,100),\n",
    "                      \"max_delta_step\": randint(0,10),\n",
    "                      \"min_child_weight\": randint(1,100),\n",
    "                      \"subsample\": randint(0.25, 0.99),\n",
    "                      \"colsample_bytree\": randint(.5, .99),\n",
    "                      #\"silent\":1,\n",
    "                      #\"num_classes\":8,\n",
    "                      \"max_depth\": randint(3,12),\n",
    "                      \"n_estimators\": randint(5,1000)\n",
    "                      }\n",
    "    \n",
    "    \n",
    "clf = XGBRegressor(silent=True)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Utility function to report best scores\n",
    "def report(grid_scores, n_top=3):\n",
    "    top_scores = sorted(grid_scores, key=itemgetter(1), reverse=True)[:n_top]\n",
    "    for i, score in enumerate(top_scores):\n",
    "        print(\"Model with rank: {0}\".format(i + 1))\n",
    "        print(\"Mean validation score: {0:.3f} (std: {1:.3f})\".format(\n",
    "              score.mean_validation_score,\n",
    "              np.std(score.cv_validation_scores)))\n",
    "        print(\"Parameters: {0}\".format(score.parameters))\n",
    "        print(\"\")\n",
    "        \n",
    "        \n",
    "        \n",
    "\n",
    "# run randomized search\n",
    "n_iter_search = 50\n",
    "random_search = RandomizedSearchCV(clf, param_distributions=param_dist,\n",
    "                                   n_iter=n_iter_search, cv=3)\n",
    "\n",
    "start = time()\n",
    "\n",
    "\n",
    "random_search.fit(X_dev, y_dev)\n",
    "print(\"RandomizedSearchCV took %.2f seconds for %d candidates\"\n",
    "      \" parameter settings.\" % ((time() - start), n_iter_search))\n",
    "report(random_search.grid_scores_)\n",
    "\n",
    "#time 512 seconds, 2 iterations, two loss measures, two learning rates\n",
    "#now trying, 50 iterations, 2x3x100x10x100x3x4x17x995, cv=3 ... low side: 12800~3hrs, high side: 9+hrs\n",
    "\n",
    "#also think about doing param tuning for PCA... i read this somewhere today, i just forgot where\n",
    "\n",
    "\n",
    "#with clf = XGBClassifier\n",
    "#RandomizedSearchCV took 87973 seconds (1466 minutes / 24 hours) for a mean validation score of 0.580 (std: 0.002)\n",
    "#params{'colsample_bytree':0.9, 'learning_rate': 0.03, 'max_delta_step': 8, 'min_child_weight':44, 'n_estimators':224,\n",
    "        #'subsample':0.75, 'objective':'count:poisson', 'max_depth':6, 'gamma':6}\n",
    "    \n",
    "#Model with rank: 2\n",
    "#Mean validation score: 0.569 (std: 0.002)\n",
    "#Parameters: {'colsample_bytree': 0.9, 'learning_rate': 0.03, 'max_delta_step': 7, 'min_child_weight': 61, 'n_estimators': 846, 'subsample': 0.75, 'objective': 'count:poisson', 'max_depth': 4, 'gamma': 15}\n",
    "\n",
    "#Model with rank: 3\n",
    "#Mean validation score: 0.566 (std: 0.001)\n",
    "#Parameters: {'colsample_bytree': 0.9, 'learning_rate': 0.01, 'max_delta_step': 4, 'min_child_weight': 77, 'n_estimators': 523, 'subsample': 0.75, 'objective': 'reg:linear', 'max_depth': 15, 'gamma': 15}\n",
    "\n",
    "\n",
    "\n",
    "#now let's try with multi-softmax\n",
    "#RandomizedSearchCV took 112468.81 seconds for 50 candidates parameter settings.\n",
    "#Model with rank: 1\n",
    "#Mean validation score: 0.579 (std: 0.002)\n",
    "#Parameters: {'colsample_bytree': 0.9, 'learning_rate': 0.01, 'max_delta_step': 1, 'min_child_weight': 82, 'n_estimators': 666, 'subsample': 0.75, 'objective': 'multi:softmax', 'max_depth': 11, 'gamma': 2}\n",
    "\n",
    "#Model with rank: 2\n",
    "#Mean validation score: 0.577 (std: 0.001)\n",
    "#Parameters: {'colsample_bytree': 1, 'learning_rate': 0.03, 'max_delta_step': 4, 'min_child_weight': 86, 'n_estimators': 877, 'subsample': 0.75, 'objective': 'multi:softmax', 'max_depth': 10, 'gamma': 8}\n",
    "\n",
    "#Model with rank: 3\n",
    "#Mean validation score: 0.569 (std: 0.003)\n",
    "#Parameters: {'colsample_bytree': 0.5, 'learning_rate': 0.001, 'max_delta_step': 4, 'min_child_weight': 1, 'n_estimators': 384, 'subsample': 0.5, 'objective': 'multi:softmax', 'max_depth': 7, 'gamma': 2}\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1466.2166666666667"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "87973/60.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#an optimizer... need to look into how to use it properly, and what it does? bayesian?\n",
    "import spearmint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomizedSearchCV took 3.26 seconds for 20 candidates parameter settings.\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.924 (std: 0.010)\n",
      "Parameters: {'bootstrap': False, 'min_samples_leaf': 4, 'min_samples_split': 6, 'criterion': 'gini', 'max_features': 9, 'max_depth': None}\n",
      "\n",
      "Model with rank: 2\n",
      "Mean validation score: 0.921 (std: 0.019)\n",
      "Parameters: {'bootstrap': False, 'min_samples_leaf': 3, 'min_samples_split': 9, 'criterion': 'entropy', 'max_features': 10, 'max_depth': None}\n",
      "\n",
      "Model with rank: 3\n",
      "Mean validation score: 0.918 (std: 0.015)\n",
      "Parameters: {'bootstrap': False, 'min_samples_leaf': 9, 'min_samples_split': 3, 'criterion': 'entropy', 'max_features': 10, 'max_depth': None}\n",
      "\n",
      "GridSearchCV took 32.67 seconds for 216 candidate parameter settings.\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.932 (std: 0.006)\n",
      "Parameters: {'bootstrap': False, 'min_samples_leaf': 1, 'min_samples_split': 1, 'criterion': 'gini', 'max_features': 10, 'max_depth': None}\n",
      "\n",
      "Model with rank: 2\n",
      "Mean validation score: 0.932 (std: 0.010)\n",
      "Parameters: {'bootstrap': True, 'min_samples_leaf': 3, 'min_samples_split': 1, 'criterion': 'entropy', 'max_features': 10, 'max_depth': None}\n",
      "\n",
      "Model with rank: 3\n",
      "Mean validation score: 0.931 (std: 0.019)\n",
      "Parameters: {'bootstrap': False, 'min_samples_leaf': 1, 'min_samples_split': 3, 'criterion': 'entropy', 'max_features': 10, 'max_depth': None}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#example code from scipy\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from time import time\n",
    "from operator import itemgetter\n",
    "from scipy.stats import randint as sp_randint\n",
    "\n",
    "from sklearn.grid_search import GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# get some data\n",
    "digits = load_digits()\n",
    "X, y = digits.data, digits.target\n",
    "\n",
    "# build a classifier\n",
    "clf = RandomForestClassifier(n_estimators=20)\n",
    "\n",
    "\n",
    "# Utility function to report best scores\n",
    "def report(grid_scores, n_top=3):\n",
    "    top_scores = sorted(grid_scores, key=itemgetter(1), reverse=True)[:n_top]\n",
    "    for i, score in enumerate(top_scores):\n",
    "        print(\"Model with rank: {0}\".format(i + 1))\n",
    "        print(\"Mean validation score: {0:.3f} (std: {1:.3f})\".format(\n",
    "              score.mean_validation_score,\n",
    "              np.std(score.cv_validation_scores)))\n",
    "        print(\"Parameters: {0}\".format(score.parameters))\n",
    "        print(\"\")\n",
    "\n",
    "\n",
    "# specify parameters and distributions to sample from\n",
    "param_dist = {\"max_depth\": [3, None],\n",
    "              \"max_features\": sp_randint(1, 11),\n",
    "              \"min_samples_split\": sp_randint(1, 11),\n",
    "              \"min_samples_leaf\": sp_randint(1, 11),\n",
    "              \"bootstrap\": [True, False],\n",
    "              \"criterion\": [\"gini\", \"entropy\"]}\n",
    "\n",
    "# run randomized search\n",
    "n_iter_search = 20\n",
    "random_search = RandomizedSearchCV(clf, param_distributions=param_dist,\n",
    "                                   n_iter=n_iter_search)\n",
    "\n",
    "start = time()\n",
    "random_search.fit(X, y)\n",
    "print(\"RandomizedSearchCV took %.2f seconds for %d candidates\"\n",
    "      \" parameter settings.\" % ((time() - start), n_iter_search))\n",
    "report(random_search.grid_scores_)\n",
    "\n",
    "# use a full grid over all parameters\n",
    "param_grid = {\"max_depth\": [3, None],\n",
    "              \"max_features\": [1, 3, 10],\n",
    "              \"min_samples_split\": [1, 3, 10],\n",
    "              \"min_samples_leaf\": [1, 3, 10],\n",
    "              \"bootstrap\": [True, False],\n",
    "              \"criterion\": [\"gini\", \"entropy\"]}\n",
    "\n",
    "# run grid search\n",
    "grid_search = GridSearchCV(clf, param_grid=param_grid)\n",
    "start = time()\n",
    "grid_search.fit(X, y)\n",
    "\n",
    "print(\"GridSearchCV took %.2f seconds for %d candidate parameter settings.\"\n",
    "      % (time() - start, len(grid_search.grid_scores_)))\n",
    "report(grid_search.grid_scores_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "No module named moe.easy_interface.experiment",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-d9f8fef73738>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mmoe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0measy_interface\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperiment\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mExperiment\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m: No module named moe.easy_interface.experiment"
     ]
    }
   ],
   "source": [
    "from moe.easy_interface.experiment import Experiment\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
